{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\embeddings.py\", line 237, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1821, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1515, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1616, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-NUkr3***************************************2b21. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
    "source": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-NUkr3***************************************2b21. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
    "details": {
        "input": [
            "PAYMENT SYSTEM:The payment system is a structured framework for processing transactions, including components like payment gateways, databases, and application servers.",
            "OPERATIONS TEAM:The operations team is responsible for the maintenance and support of the payment system, providing assistance and troubleshooting.",
            "PROMETHEUS:Prometheus is a monitoring tool used to track the performance and health of the payment system.",
            "GRAFANA:Grafana is a visualization tool that works with Prometheus to display metrics and alerts for the payment system.",
            "SYSTEM DOWNTIME:System downtime refers to periods when the payment system is unavailable, impacting transaction processing.",
            "PAYMENT FAILURE:Payment failure occurs when transactions do not complete successfully due to various issues.",
            "DATA ENCRYPTION:Data encryption is a security practice involving the use of TLS and AES to protect sensitive information in the payment system.",
            "BACKUP AND RECOVERY:Backup and recovery procedures are critical processes for restoring the payment system in case of failure.",
            "LOAD TESTING:Load testing is an evaluation method used to assess the performance of the payment system under various conditions.",
            "COMMON ISSUES AND SOLUTIONS:Common issues and solutions provide guidance on troubleshooting problems that may arise within the payment system.",
            "MONITORING AND ALERTS:Monitoring and alerts involve tracking system performance and setting up notifications for critical issues.",
            "SECURITY BEST PRACTICES:Security best practices outline measures to protect the payment system from vulnerabilities and threats.",
            "PERFORMANCE OPTIMIZATION:Performance optimization includes strategies to enhance the efficiency and speed of the payment system.",
            "SYSTEM ARCHITECTURE:"
        ]
    }
}
{
    "type": "error",
    "data": "Error executing verb \"text_embed\" in create_final_entities: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-NUkr3***************************************2b21. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
    "stack": "Traceback (most recent call last):\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\text_embed.py\", line 105, in text_embed\n    return await _text_embed_in_memory(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\text_embed.py\", line 130, in _text_embed_in_memory\n    result = await strategy_exec(texts, callbacks, cache, strategy_args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\strategies\\openai.py\", line 62, in run\n    embeddings = await _execute(llm, text_batches, ticker, semaphore)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\strategies\\openai.py\", line 106, in _execute\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\strategies\\openai.py\", line 100, in embed\n    chunk_embeddings = await llm(chunk)\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\embeddings.py\", line 237, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1821, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1515, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1616, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-NUkr3***************************************2b21. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
    "source": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-NUkr3***************************************2b21. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
    "details": null
}
{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\run\\run.py\", line 227, in run_pipeline\n    result = await _process_workflow(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\run\\workflow.py\", line 91, in _process_workflow\n    result = await workflow.run(context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\text_embed.py\", line 105, in text_embed\n    return await _text_embed_in_memory(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\text_embed.py\", line 130, in _text_embed_in_memory\n    result = await strategy_exec(texts, callbacks, cache, strategy_args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\strategies\\openai.py\", line 62, in run\n    embeddings = await _execute(llm, text_batches, ticker, semaphore)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\strategies\\openai.py\", line 106, in _execute\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\index\\verbs\\text\\embed\\strategies\\openai.py\", line 100, in embed\n    chunk_embeddings = await llm(chunk)\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\embeddings.py\", line 237, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1821, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1515, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hiron\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1616, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-NUkr3***************************************2b21. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
    "source": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-NUkr3***************************************2b21. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
    "details": null
}
